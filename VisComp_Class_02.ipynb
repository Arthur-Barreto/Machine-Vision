{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Arthur-Barreto/Machine-Vision/blob/main/VisComp_Class_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Class 2: Neural Networks"
      ],
      "metadata": {
        "id": "ldormuK39mU1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preliminaries"
      ],
      "metadata": {
        "id": "Ot_LD8I8AOQ6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the cell below to download the class pack."
      ],
      "metadata": {
        "id": "jrA0L5tPd_aG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "\n",
        "gdown.download(id='1HyzfGz13lLENHkZER2sbi4mqcRN2XHuM')\n",
        "\n",
        "!unzip -o '02.zip'\n",
        "!rm '02.zip'"
      ],
      "metadata": {
        "id": "fMqO3xXod_fM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the cell below to import the class modules.\n",
        "\n",
        "If you get import warnings, try using **Ctrl+m .** (notice there is a dot there) to restart the kernel."
      ],
      "metadata": {
        "id": "qLYdrANx9t0n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "from sdx import *\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "x3QrEMEhje9z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the MNIST dataset"
      ],
      "metadata": {
        "id": "3ZG8DhOSj3Pe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The [MNIST dataset](http://yann.lecun.com/exdb/mnist/) is a famous database of handwritten digits."
      ],
      "metadata": {
        "id": "QopzKv3ZkGuJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = keras.datasets.mnist.load_data()"
      ],
      "metadata": {
        "id": "Y-TeDhsQj3TO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The variable `train_images` is an array of 60000 images that should be used as training data. Below, we see the tenth image."
      ],
      "metadata": {
        "id": "9V8vxKsTj3Wz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cv_imshow(train_images[9])"
      ],
      "metadata": {
        "id": "Nlt5eAQij3an"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The variable `train_labels` is an array of 60000 integers, which are the respective labels of these images. These integers were obtained manually, so they are reliable to use as groundtruth. Below, we see the label of the tenth image."
      ],
      "metadata": {
        "id": "rriNJaajnROG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels[9]"
      ],
      "metadata": {
        "id": "Gi16KBipnRRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The variable `test_images` is an array of 10000 images that should be used as test data."
      ],
      "metadata": {
        "id": "U6kteUCCnRXC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cv_imshow(test_images[-1])"
      ],
      "metadata": {
        "id": "Io2aoaaVowcz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, the variable `test_labels` is an array of 10000 integers, which are the respective labels."
      ],
      "metadata": {
        "id": "Yo__SKGBnRZo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels[-1]"
      ],
      "metadata": {
        "id": "Y-yMEhmrnRcF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To show more than one image at once, we can call the `cv_gridshow` function, passing the array and the parameters of a slice. Below, we show the 25 images that correspond to the `train_images[10:35]` slice."
      ],
      "metadata": {
        "id": "nYEVdKw-nRes"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cv_gridshow(train_images, start=10, stop=35)"
      ],
      "metadata": {
        "id": "482kCZQWnRlB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is possible to show the labels alongside the images."
      ],
      "metadata": {
        "id": "yyrykFIukIk9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cv_gridshow(train_images, start=10, stop=35, labels=train_labels)"
      ],
      "metadata": {
        "id": "cOmJ9jlqj3gu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The default value for `start` is `0` and the default value for `stop` is `9`. This is important because the processing happens in Google servers but the rendering still happens in your machine. If you accidentally tried to show 60000 images at once, your browser would probably die horribly."
      ],
      "metadata": {
        "id": "8pMsX8aTj3iv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cv_gridshow(train_images)"
      ],
      "metadata": {
        "id": "JgLN_Voyj3le"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building neural networks"
      ],
      "metadata": {
        "id": "5aD5xn2Aj3uL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's build a first neural network. More accurately, let's *demonstrate the foundations of building a neural network.* The actual model we will build is so trivial that we can't really call it an actual neural network, since it will have no hidden layers."
      ],
      "metadata": {
        "id": "z4zgbIe7j3xp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Firstly, let's reshape the training images and testing images. The dataset is available as 2D arrays, but the model expects 1D arrays, so we must concatenate the image rows to turn the 28x28 arrays into 1x784 arrays."
      ],
      "metadata": {
        "id": "GAb174Cy7BNO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = train_images.reshape(60000, 784)\n",
        "test_images = test_images.reshape(10000, 784)"
      ],
      "metadata": {
        "id": "7ikDnuE6j33G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, let's build the *input layer,* calling the `keras.Input` constructor. It obviously needs to know the size of the inputs."
      ],
      "metadata": {
        "id": "7hbbTqOTsxdS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = keras.Input(shape=(784,))"
      ],
      "metadata": {
        "id": "jyuwUX-psxfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, let's build the *output layer,* which will always be a *dense layer* in our networks. We do this by calling the `keras.layers.Dense` constructor. Since we are building a *categorical* classifier, it needs to know the number of categories, which is the number of possible digits."
      ],
      "metadata": {
        "id": "xcPAvmVN8lfS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layer = keras.layers.Dense(10)"
      ],
      "metadata": {
        "id": "VKE5wFKUsxiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This constructor actually returns a function. In order to have the actual layer, we need to call this function."
      ],
      "metadata": {
        "id": "pWWSGz4P9bWm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = layer(inputs)"
      ],
      "metadata": {
        "id": "sfFGOl_j9baG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now have what we need to compile the model. We won't delve into the details today, but the parameters below are necessary to ensure that an adequate model for our problem is compiled."
      ],
      "metadata": {
        "id": "cPrh9Dmi9ybe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compile_model(inputs, outputs):\n",
        "    model = keras.Model(inputs, outputs)\n",
        "    model.compile(\n",
        "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "        metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
        "    )\n",
        "    return model"
      ],
      "metadata": {
        "id": "yUQ26jg72VXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = compile_model(inputs, outputs)"
      ],
      "metadata": {
        "id": "cjgMxEpLsxkt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To confirm that the model is structured as expected, we can call the `model.summary` method."
      ],
      "metadata": {
        "id": "niN5YueR-NXG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "YUP4k0H8sxna"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we are ready to train our model, calling `model.fit`..."
      ],
      "metadata": {
        "id": "H9fSw0z7-YbR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_images, train_labels);"
      ],
      "metadata": {
        "id": "ms3luccCsxqM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "...and test it, calling `model.evaluate`."
      ],
      "metadata": {
        "id": "fnA6UmGM-eBn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_images, test_labels);"
      ],
      "metadata": {
        "id": "nMmyZce7sxtM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A more detailed evaluation of the model can be seen via the *confusion matrix.*"
      ],
      "metadata": {
        "id": "z44dbMs0-vFF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion(model, test_images, test_labels)"
      ],
      "metadata": {
        "id": "XSuQkaB2xPdJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**STOP HERE! WAIT FOR THE TEACHER BEFORE PROCEEDING!**"
      ],
      "metadata": {
        "id": "hYmKL8zA_I1Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building a single-layer neural network"
      ],
      "metadata": {
        "id": "_6_kArXWj4BA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layer = keras.layers.Dense(397)\n",
        "outputs = layer(inputs)\n",
        "\n",
        "layer = keras.layers.Dense(10)\n",
        "outputs = layer(outputs)\n",
        "\n",
        "model = compile_model(inputs, outputs)\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "7kc76lQEkN_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_images, train_labels)\n",
        "\n",
        "model.evaluate(test_images, test_labels)\n",
        "\n",
        "plot_confusion(model, test_images, test_labels)"
      ],
      "metadata": {
        "id": "anycX9NZkOFs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extra"
      ],
      "metadata": {
        "id": "1RZH6nSLVcjy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using relu as activation\n",
        "-> First Layer"
      ],
      "metadata": {
        "id": "hAyt5_vLX-6J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layer = keras.layers.Dense(397, activation = 'relu')\n",
        "outputs = layer(inputs)\n",
        "\n",
        "layer = keras.layers.Dense(10)\n",
        "outputs = layer(outputs)\n",
        "\n",
        "model = compile_model(inputs, outputs)\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "tSANH1BFYGFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_images, train_labels)\n",
        "\n",
        "model.evaluate(test_images, test_labels)\n",
        "\n",
        "plot_confusion(model, test_images, test_labels)"
      ],
      "metadata": {
        "id": "GEGR-JMmYKmS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "USing 'relu' on the last layer"
      ],
      "metadata": {
        "id": "rlFNAvenZELN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layer = keras.layers.Dense(397)\n",
        "outputs = layer(inputs)\n",
        "\n",
        "layer = keras.layers.Dense(10, activation = 'relu')\n",
        "outputs = layer(outputs)\n",
        "\n",
        "model = compile_model(inputs, outputs)\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "_UlPFuzMZH8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_images, train_labels)\n",
        "\n",
        "model.evaluate(test_images, test_labels)\n",
        "\n",
        "plot_confusion(model, test_images, test_labels)"
      ],
      "metadata": {
        "id": "FnXR-9NcZKdK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion"
      ],
      "metadata": {
        "id": "f6qVbvdlYkH3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The better model use 'relu' as actiavation function, however, when we used on the last layer, we got less than 10 % accuracy."
      ],
      "metadata": {
        "id": "G-esZSjRYm27"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can click on the ![toc.png](data:image/png;base64,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) tab to the left to browse by section."
      ],
      "metadata": {
        "id": "yeqlUsEC6lqA"
      }
    }
  ]
}